{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e18495e",
   "metadata": {},
   "source": [
    "# Explaining Music Recommendations through Audio Features and Spectrogram Analysis\n",
    "\n",
    "**Team 4:** Anna-Mariia Chornohuz (h12014626) and Iana Schnattler (h11831531)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1848d",
   "metadata": {},
   "source": [
    "# 1. Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b218e36",
   "metadata": {},
   "source": [
    "# Project Overview: Spectrogram-Based Explainability in Music Recommender Systems\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Music recommender systems have become essential components of streaming platforms such as **Spotify**, **Apple Music**, and **Deezer**. These systems aim to increase user satisfaction and engagement by providing **personalized track suggestions** based on past listening behavior, inferred preferences, and contextual variables. Despite their success, a critical challenge remains: **explainability**—that is, the ability to convey to users why a particular song was recommended.\n",
    "\n",
    "Explainable recommender systems (XRS) are especially relevant in domains like music, where preferences are **subjective, emotional, and context-sensitive**. Prior work has demonstrated that when users understand the reasoning behind recommendations, their trust and adoption rates increase (Zhang & Chen, 2018). However, most platforms today provide little to no insight into the underlying logic behind their recommendations.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Limitations of Traditional Systems\n",
    "\n",
    "Most existing systems are based on two fundamental approaches:\n",
    "- **Collaborative Filtering (CF)**: Recommends items liked by users with similar behavior.\n",
    "- **Content-Based Filtering (CBF)**: Recommends items based on the features of previously liked items (e.g., tempo, energy, valence, etc.).\n",
    "\n",
    "These features, while powerful, are typically **invisible to users** and highly technical, which makes human-centered explanations difficult. A user is unlikely to find it meaningful to hear that a song was recommended because it has a high “zero-crossing rate” or “spectral centroid” (Nam et al., 2022).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Post-Hoc Explainability Techniques\n",
    "\n",
    "Recent advances in explainable AI (XAI) have led to the adoption of **model-agnostic techniques** such as:\n",
    "- **LIME** (Local Interpretable Model-Agnostic Explanations)\n",
    "- **SHAP** (SHapley Additive exPlanations)\n",
    "\n",
    "These methods explain the model's decision by identifying which input features most contributed to the output. However, their reliance on low-level numeric features **limits user interpretability**, especially in music, where emotional and perceptual aspects dominate (Lundberg & Lee, 2017; Ribeiro et al., 2016; Marconi et al., 2023).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Spectrograms as Perceptual Explanation Tools\n",
    "\n",
    "A **spectrogram** is a visual representation of an audio signal’s frequency content over time. It captures structural elements of sound such as:\n",
    "- Rhythm\n",
    "- Timbre\n",
    "- Pitch contours\n",
    "- Instrumentation\n",
    "\n",
    "Unlike numeric features, **spectrograms preserve the sonic character** of a track, allowing for intuitive, human-interpretable comparisons between songs. Spectrograms can effectively “show” the texture of music, acting as a bridge between signal-level data and human perception (Müller, 2015).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Proposed Method\n",
    "\n",
    "This project proposes a **hybrid recommendation-explanation system** that:\n",
    "1. Uses standard audio features (e.g., tempo, RMS, spectral centroid) for similarity-based recommendation.\n",
    "2. Generates **spectrograms** from raw audio and uses them to both:\n",
    "   - **Inform** deep learning models trained on image-based representations.\n",
    "   - **Explain** recommendations visually to users.\n",
    "\n",
    "By comparing spectrograms of a liked track and its recommendation, users can **visually perceive similarities** in structure, rhythm, or tonal content. This bridges the gap between black-box recommendation logic and perceptual user understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Comparative Evaluation\n",
    "\n",
    "We will compare:\n",
    "- **Feature-based similarity** models (e.g., cosine distance on tempo, RMS, ZCR).\n",
    "- **Spectrogram-based CNN models** (trained to predict similarity based on visual data).\n",
    "- **User feedback** on perceived clarity and trustworthiness of explanations.\n",
    "\n",
    "Relevant previous work includes deep learning-based music classification using spectrograms and CNNs (e.g., ResNet-50, VGG-16), and feature-based interpretability studies (Nam et al., 2022).\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Contribution to Explainable AI (XAI)\n",
    "\n",
    "This work contributes to the XAI and **human-centered AI design** communities by:\n",
    "- Introducing perceptually aligned explanations in music recommendation.\n",
    "- Exploring **spectrograms as both input and explanation** tools.\n",
    "- Highlighting how users can interact with visual data to enhance trust and satisfaction.\n",
    "\n",
    "Ultimately, this approach seeks to make music recommendation not only accurate but also **transparent, interpretable, and emotionally resonant**.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Next Steps\n",
    "\n",
    "- Implement spectrogram extraction and visualization.\n",
    "- Train CNN or similarity-based models on spectrograms.\n",
    "- Compare outputs with traditional feature-based models.\n",
    "- Conduct user testing to evaluate **interpretability and trust**.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- Zhang, Y., & Chen, X. (2020). *Explainable Recommendation: A Survey and New Perspectives*. Foundations and Trends® in Information Retrieval, 14(1), 1–101. \n",
    "- Lundberg, S. M., & Lee, S.-I. (2017). *A Unified Approach to Interpreting Model Predictions*. Advances in Neural Information Processing Systems, 30.  \n",
    "- Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). *“Why Should I Trust You?”: Explaining the Predictions of Any Classifier*. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1135–1144.  \n",
    "- Marconi, L., Matamoros Aragón, R., & Epifania, F. (2023). *A Short Review on Explainability for Recommender Systems*. CEUR Workshop Proceedings, Vol. 3463.  \n",
    "- Müller, M. (2015). *Fundamentals of Music Processing: Audio, Analysis, Algorithms, Applications*. Springer.  \n",
    "- Nam, J., Herrera, J., Slaney, M., & Smith III, J. O. (2012, October). Learning Sparse Feature Representations for Music Annotation and Retrieval. In ISMIR (pp. 565-570). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633a73f",
   "metadata": {},
   "source": [
    "# 2. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d5de4",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e22cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>track_name_lc</th>\n",
       "      <th>artist_lc</th>\n",
       "      <th>deezer_item_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1JiR4RJaZlbZ5b3HG8jkeL</td>\n",
       "      <td>Longtime (feat. Skepta)</td>\n",
       "      <td>Wizkid;Skepta</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.622</td>\n",
       "      <td>101.947</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>dancehall</td>\n",
       "      <td>longtime (feat. skepta)</td>\n",
       "      <td>wizkid;skepta</td>\n",
       "      <td>58552</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6cfNBFSKFB59wO8xIFZ0qI</td>\n",
       "      <td>Dom na wiślanym brzegu</td>\n",
       "      <td>Ivan komarenko</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.849</td>\n",
       "      <td>106.978</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>disco</td>\n",
       "      <td>dom na wiślanym brzegu</td>\n",
       "      <td>ivan komarenko</td>\n",
       "      <td>15195</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5VcFzH97JEHgXgedErp4cP</td>\n",
       "      <td>Idea 686</td>\n",
       "      <td>Jayla Darden</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.500</td>\n",
       "      <td>135.975</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>chill</td>\n",
       "      <td>idea 686</td>\n",
       "      <td>jayla darden</td>\n",
       "      <td>340815</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7oMBY3VmIxqNVeZ7yneYuN</td>\n",
       "      <td>Me Voy Enamorando</td>\n",
       "      <td>Chino &amp; Nacho</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.511</td>\n",
       "      <td>99.952</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>electro</td>\n",
       "      <td>me voy enamorando</td>\n",
       "      <td>chino &amp; nacho</td>\n",
       "      <td>265475</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7g8U2TPh6JPFJK5LgqsNeE</td>\n",
       "      <td>What I've Done</td>\n",
       "      <td>Linkin Park</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.287</td>\n",
       "      <td>120.119</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>grunge</td>\n",
       "      <td>what i've done</td>\n",
       "      <td>linkin park</td>\n",
       "      <td>327431</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id               track_name         artists  \\\n",
       "0  1JiR4RJaZlbZ5b3HG8jkeL  Longtime (feat. Skepta)   Wizkid;Skepta   \n",
       "1  6cfNBFSKFB59wO8xIFZ0qI   Dom na wiślanym brzegu  Ivan komarenko   \n",
       "2  5VcFzH97JEHgXgedErp4cP                 Idea 686    Jayla Darden   \n",
       "3  7oMBY3VmIxqNVeZ7yneYuN        Me Voy Enamorando   Chino & Nacho   \n",
       "4  7g8U2TPh6JPFJK5LgqsNeE           What I've Done     Linkin Park   \n",
       "\n",
       "   danceability  energy  valence    tempo  acousticness  instrumentalness  \\\n",
       "0         0.850   0.660    0.622  101.947        0.4170          0.000051   \n",
       "1         0.640   0.758    0.849  106.978        0.4970          0.000000   \n",
       "2         0.712   0.347    0.500  135.975        0.3780          0.021200   \n",
       "3         0.686   0.912    0.511   99.952        0.0533          0.000000   \n",
       "4         0.623   0.930    0.287  120.119        0.0141          0.000002   \n",
       "\n",
       "   speechiness track_genre            track_name_lc       artist_lc  \\\n",
       "0       0.1690   dancehall  longtime (feat. skepta)   wizkid;skepta   \n",
       "1       0.0675       disco   dom na wiślanym brzegu  ivan komarenko   \n",
       "2       0.0410       chill                 idea 686    jayla darden   \n",
       "3       0.0685     electro        me voy enamorando   chino & nacho   \n",
       "4       0.0324      grunge           what i've done     linkin park   \n",
       "\n",
       "   deezer_item_id country  \n",
       "0           58552      DE  \n",
       "1           15195      DE  \n",
       "2          340815      FR  \n",
       "3          265475      FR  \n",
       "4          327431      US  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df_deezer = pd.read_csv(\"Deezer Data/metadata_DEEZER_active.csv\")\n",
    "df_spotify = pd.read_csv(\"Spotify Data/train.csv\")\n",
    "\n",
    "# Clean Deezer data\n",
    "df_deezer_clean = df_deezer.dropna(subset=[\"country\"]).copy()\n",
    "df_deezer_clean = df_deezer_clean.rename(columns={\"item_id\": \"deezer_item_id\"})\n",
    "\n",
    "# Clean Spotify data\n",
    "df_spotify_clean = df_spotify[[\n",
    "    \"track_id\", \"track_name\", \"artists\", \"danceability\", \"energy\", \"valence\",\n",
    "    \"tempo\", \"acousticness\", \"instrumentalness\", \"speechiness\", \"track_genre\"\n",
    "]].dropna()\n",
    "df_spotify_clean[\"track_name_lc\"] = df_spotify_clean[\"track_name\"].str.lower().str.strip()\n",
    "df_spotify_clean[\"artist_lc\"] = df_spotify_clean[\"artists\"].str.lower().str.strip()\n",
    "\n",
    "# Simulate matched tracks (random pairing)\n",
    "sample_matched_spotify = df_spotify_clean.sample(n=100, random_state=1).copy()\n",
    "sample_matched_spotify[\"deezer_item_id\"] = df_deezer_clean[\"deezer_item_id\"].sample(n=100, random_state=2).values\n",
    "\n",
    "# Merge to add country info\n",
    "df_matched = pd.merge(sample_matched_spotify, df_deezer_clean, on=\"deezer_item_id\")\n",
    "df_matched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cededaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched 1 of 200 with cleaned matching.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name_x</th>\n",
       "      <th>artists_x</th>\n",
       "      <th>track_name_y</th>\n",
       "      <th>artists_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Traumtänzerball (Album Version)</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Traumtänzerball</td>\n",
       "      <td>Michelle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      track_name_x artists_x     track_name_y artists_y\n",
       "0  Traumtänzerball (Album Version)  Michelle  Traumtänzerball  Michelle"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Helper to clean titles\n",
    "def clean_title(title):\n",
    "    if pd.isna(title):\n",
    "        return None\n",
    "    title = title.lower()\n",
    "    title = re.sub(r\"\\(.*?\\)\", \"\", title)  # remove anything in ( )\n",
    "    title = re.sub(r\"/.*\", \"\", title)      # remove anything after /\n",
    "    title = re.sub(r\"[^a-z0-9\\s]\", \"\", title)  # remove punctuation\n",
    "    return title.strip()\n",
    "\n",
    "# Helper to extract primary artist\n",
    "def clean_artist(artist):\n",
    "    if pd.isna(artist):\n",
    "        return None\n",
    "    artist = artist.lower()\n",
    "    artist = artist.split(\";\")[0]  # only first artist\n",
    "    artist = re.sub(r\"(feat\\.|with).*\", \"\", artist)  # remove 'feat.', 'with'\n",
    "    artist = re.sub(r\"[^a-z0-9\\s]\", \"\", artist)  # remove punctuation\n",
    "    return artist.strip()\n",
    "\n",
    "# Apply to both datasets\n",
    "df_deezer_enriched[\"track_name_clean\"] = df_deezer_enriched[\"track_name\"].apply(clean_title)\n",
    "df_deezer_enriched[\"artist_clean\"] = df_deezer_enriched[\"artists\"].apply(clean_artist)\n",
    "\n",
    "df_spotify_clean[\"track_name_clean\"] = df_spotify_clean[\"track_name\"].apply(clean_title)\n",
    "df_spotify_clean[\"artist_clean\"] = df_spotify_clean[\"artists\"].apply(clean_artist)\n",
    "\n",
    "# Now merge on cleaned fields\n",
    "df_matched = pd.merge(\n",
    "    df_deezer_enriched,\n",
    "    df_spotify_clean,\n",
    "    on=[\"track_name_clean\", \"artist_clean\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Deduplicate\n",
    "df_matched = (\n",
    "    df_matched\n",
    "    .sort_values(\"valence\", ascending=False)\n",
    "    .drop_duplicates(subset=[\"deezer_item_id\"])\n",
    ")\n",
    "\n",
    "# Save\n",
    "df_matched.to_csv(\"Matched Data/deezer_spotify_matched_200_cleaned.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Matched {len(df_matched)} of 200 with cleaned matching.\")\n",
    "display(df_matched[[\"track_name_x\", \"artists_x\", \"track_name_y\", \"artists_y\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f873c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.9.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96e0f0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎵 Sample from enriched Deezer data:\n",
      "                                           track_name                 artists\n",
      "4                         Air (Johann Sebastian Bach)            Ed Staginsky\n",
      "7                             Grande Fratello (remix)      Roberto Delledonne\n",
      "8                                             My Life         Mortimer Shuman\n",
      "9                                            Carousel         Michael Jackson\n",
      "10                          Quincy Jones Interview #3            Quincy Jones\n",
      "14        Goodbye (na na na) (Original Radio Version)                   Rob M\n",
      "16  Voice-Over Intro / Voice-Over Session from Thr...         Michael Jackson\n",
      "17                                              Untha  Les Secrets De Morphee\n",
      "20                           A march for new european            Jack Or Jive\n",
      "21  The Girl Is Mine (2008 with will.i.am) (with w...         Michael Jackson\n",
      "\n",
      "🎧 Sample from Spotify data:\n",
      "                   track_name                               artists\n",
      "0                      Comedy                           Gen Hoshino\n",
      "1            Ghost - Acoustic                          Ben Woodward\n",
      "2              To Begin Again                Ingrid Michaelson;ZAYN\n",
      "3  Can't Help Falling In Love                          Kina Grannis\n",
      "4                     Hold On                      Chord Overstreet\n",
      "5        Days I Will Remember                          Tyrone Wells\n",
      "6               Say Something  A Great Big World;Christina Aguilera\n",
      "7                   I'm Yours                            Jason Mraz\n",
      "8                       Lucky             Jason Mraz;Colbie Caillat\n",
      "9                      Hunger                        Ross Copperman\n"
     ]
    }
   ],
   "source": [
    "print(\"🎵 Sample from enriched Deezer data:\")\n",
    "print(df_deezer_enriched[[\"track_name\", \"artists\"]].dropna().drop_duplicates().head(10))\n",
    "\n",
    "print(\"\\n🎧 Sample from Spotify data:\")\n",
    "print(df_spotify_clean[[\"track_name\", \"artists\"]].dropna().drop_duplicates().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23578798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Fuzzy-matched 1 Deezer tracks (score ≥ 90)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name_x</th>\n",
       "      <th>artists_x</th>\n",
       "      <th>track_name_y</th>\n",
       "      <th>artists_y</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Traumtänzerball (Album Version)</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Traumtänzerball</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      track_name_x artists_x     track_name_y artists_y  \\\n",
       "0  Traumtänzerball (Album Version)  Michelle  Traumtänzerball  Michelle   \n",
       "\n",
       "   match_score  \n",
       "0        100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine title and artist for matching\n",
    "df_deezer_enriched[\"match_key\"] = df_deezer_enriched[\"track_name_clean\"] + \" - \" + df_deezer_enriched[\"artist_clean\"]\n",
    "df_spotify_clean[\"match_key\"] = df_spotify_clean[\"track_name_clean\"] + \" - \" + df_spotify_clean[\"artist_clean\"]\n",
    "\n",
    "spotify_keys = df_spotify_clean[\"match_key\"].dropna().unique().tolist()\n",
    "\n",
    "# Updated safe function\n",
    "def find_best_match(deezer_key):\n",
    "    if pd.isna(deezer_key) or not isinstance(deezer_key, str) or deezer_key.strip() == \"\":\n",
    "        return pd.Series([None, 0])\n",
    "    \n",
    "    result = process.extractOne(deezer_key, spotify_keys, scorer=fuzz.token_sort_ratio)\n",
    "    if result is None:\n",
    "        return pd.Series([None, 0])\n",
    "    \n",
    "    match, score, _ = result\n",
    "    return pd.Series([match, score])\n",
    "\n",
    "# Apply to 200 entries\n",
    "df_sample = df_deezer_enriched.head(200).copy()\n",
    "df_sample[[\"best_match\", \"match_score\"]] = df_sample[\"match_key\"].apply(find_best_match)\n",
    "\n",
    "# Filter and merge\n",
    "df_matches_fuzzy = df_sample[df_sample[\"match_score\"] >= 90].copy()\n",
    "df_spotify_subset = df_spotify_clean[[\"match_key\", \"track_id\", \"track_name\", \"artists\", \"danceability\", \"energy\", \"valence\",\n",
    "    \"tempo\", \"acousticness\", \"instrumentalness\", \"speechiness\", \"track_genre\"]]\n",
    "\n",
    "df_final_fuzzy = pd.merge(\n",
    "    df_matches_fuzzy,\n",
    "    df_spotify_subset,\n",
    "    left_on=\"best_match\",\n",
    "    right_on=\"match_key\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_final_fuzzy.to_csv(\"Matched Data/deezer_spotify_matched_200_fuzzy.csv\", index=False)\n",
    "\n",
    "print(f\"🤖 Fuzzy-matched {len(df_final_fuzzy)} Deezer tracks (score ≥ 90)\")\n",
    "display(df_final_fuzzy[[\"track_name_x\", \"artists_x\", \"track_name_y\", \"artists_y\", \"match_score\"]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff41264",
   "metadata": {},
   "source": [
    "## Step 2: Spectrogram Preparation and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956f8a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>speechiness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1JiR4RJaZlbZ5b3HG8jkeL</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.622</td>\n",
       "      <td>101.947</td>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6cfNBFSKFB59wO8xIFZ0qI</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.849</td>\n",
       "      <td>106.978</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5VcFzH97JEHgXgedErp4cP</th>\n",
       "      <td>0.712</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.500</td>\n",
       "      <td>135.975</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.0410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7oMBY3VmIxqNVeZ7yneYuN</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.511</td>\n",
       "      <td>99.952</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7g8U2TPh6JPFJK5LgqsNeE</th>\n",
       "      <td>0.623</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.287</td>\n",
       "      <td>120.119</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        danceability  energy  valence    tempo  acousticness  \\\n",
       "track_id                                                                       \n",
       "1JiR4RJaZlbZ5b3HG8jkeL         0.850   0.660    0.622  101.947        0.4170   \n",
       "6cfNBFSKFB59wO8xIFZ0qI         0.640   0.758    0.849  106.978        0.4970   \n",
       "5VcFzH97JEHgXgedErp4cP         0.712   0.347    0.500  135.975        0.3780   \n",
       "7oMBY3VmIxqNVeZ7yneYuN         0.686   0.912    0.511   99.952        0.0533   \n",
       "7g8U2TPh6JPFJK5LgqsNeE         0.623   0.930    0.287  120.119        0.0141   \n",
       "\n",
       "                        instrumentalness  speechiness  \n",
       "track_id                                               \n",
       "1JiR4RJaZlbZ5b3HG8jkeL          0.000051       0.1690  \n",
       "6cfNBFSKFB59wO8xIFZ0qI          0.000000       0.0675  \n",
       "5VcFzH97JEHgXgedErp4cP          0.021200       0.0410  \n",
       "7oMBY3VmIxqNVeZ7yneYuN          0.000000       0.0685  \n",
       "7g8U2TPh6JPFJK5LgqsNeE          0.000002       0.0324  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate spectrogram placeholder paths\n",
    "df_matched[\"spectrogram_path\"] = df_matched.apply(\n",
    "    lambda row: f\"spectrograms/{row['track_name'].replace('/', '-')}_{row['artists'].split(';')[0]}.png\", axis=1\n",
    ")\n",
    "\n",
    "# Extract audio features\n",
    "feature_cols = ['danceability', 'energy', 'valence', 'tempo', 'acousticness', 'instrumentalness', 'speechiness']\n",
    "df_features = df_matched[['track_id'] + feature_cols].set_index('track_id')\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe5ce8",
   "metadata": {},
   "source": [
    "## Step 3: Build Content-Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7870f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0CyiCor3YLnPcBkZ04cLz2</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.939</td>\n",
       "      <td>109.892</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24SDeYAeTFda8OUzVI1VR6</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.635</td>\n",
       "      <td>106.253</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6cfNBFSKFB59wO8xIFZ0qI</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.849</td>\n",
       "      <td>106.978</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id  danceability  energy  valence    tempo  \\\n",
       "0  0CyiCor3YLnPcBkZ04cLz2         0.823   0.782    0.939  109.892   \n",
       "1  24SDeYAeTFda8OUzVI1VR6         0.571   0.747    0.635  106.253   \n",
       "2  6cfNBFSKFB59wO8xIFZ0qI         0.640   0.758    0.849  106.978   \n",
       "\n",
       "   acousticness  instrumentalness  speechiness  similarity  \n",
       "0         0.391               0.0       0.1980    0.999996  \n",
       "1         0.478               0.0       0.1700    0.999995  \n",
       "2         0.497               0.0       0.0675    0.999995  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_recommendations(track_id, df_features, top_n=3):\n",
    "    if track_id not in df_features.index:\n",
    "        return pd.DataFrame()\n",
    "    track_vec = df_features.loc[[track_id]]\n",
    "    rest = df_features.drop(index=track_id)\n",
    "    similarities = cosine_similarity(track_vec, rest)[0]\n",
    "    rest = rest.copy()\n",
    "    rest['similarity'] = similarities\n",
    "    return rest.sort_values('similarity', ascending=False).head(top_n)\n",
    "\n",
    "# Pick one reference track\n",
    "reference_id = df_features.index[0]\n",
    "recommended_df = get_recommendations(reference_id, df_features, top_n=3).reset_index()\n",
    "recommended_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c6f3e",
   "metadata": {},
   "source": [
    "## Step 4: Visual Comparison Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce780a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artists</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>spectrogram_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Longtime (feat. Skepta)</td>\n",
       "      <td>Wizkid;Skepta</td>\n",
       "      <td>dancehall</td>\n",
       "      <td>spectrograms/Longtime (feat. Skepta)_Wizkid.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dom na wiślanym brzegu</td>\n",
       "      <td>Ivan komarenko</td>\n",
       "      <td>disco</td>\n",
       "      <td>spectrograms/Dom na wiślanym brzegu_Ivan komar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weh Di Time</td>\n",
       "      <td>Voicemail;Delly Ranks;Bogle</td>\n",
       "      <td>j-dance</td>\n",
       "      <td>spectrograms/Weh Di Time_Voicemail.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TWIST &amp; TURN (feat. Drake &amp; PARTYNEXTDOOR)</td>\n",
       "      <td>Popcaan;Drake;PARTYNEXTDOOR</td>\n",
       "      <td>dancehall</td>\n",
       "      <td>spectrograms/TWIST &amp; TURN (feat. Drake &amp; PARTY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   track_name                      artists  \\\n",
       "0                     Longtime (feat. Skepta)                Wizkid;Skepta   \n",
       "1                      Dom na wiślanym brzegu               Ivan komarenko   \n",
       "2                                 Weh Di Time  Voicemail;Delly Ranks;Bogle   \n",
       "3  TWIST & TURN (feat. Drake & PARTYNEXTDOOR)  Popcaan;Drake;PARTYNEXTDOOR   \n",
       "\n",
       "  track_genre                                   spectrogram_path  \n",
       "0   dancehall    spectrograms/Longtime (feat. Skepta)_Wizkid.png  \n",
       "1       disco  spectrograms/Dom na wiślanym brzegu_Ivan komar...  \n",
       "2     j-dance             spectrograms/Weh Di Time_Voicemail.png  \n",
       "3   dancehall  spectrograms/TWIST & TURN (feat. Drake & PARTY...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare combined view of reference + recommended tracks\n",
    "reference_row = df_matched[df_matched['track_id'] == reference_id]\n",
    "recommend_rows = df_matched[df_matched['track_id'].isin(recommended_df['track_id'])]\n",
    "visual_compare = pd.concat([reference_row, recommend_rows], axis=0).reset_index(drop=True)\n",
    "visual_compare[[\"track_name\", \"artists\", \"track_genre\", \"spectrogram_path\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da367b3b",
   "metadata": {},
   "source": [
    "# 3. Spectrogram Generation and Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1f188",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e37b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "output_dir = Path(\"spectrograms\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f26212",
   "metadata": {},
   "source": [
    "## Step 2: Spectrogram Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b30b00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative spectrogram generation using scipy to avoid librosa/numba issues\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "def generate_spectrogram(audio_path, save_path):\n",
    "    sr, y = wavfile.read(audio_path)\n",
    "    f, t, Sxx = spectrogram(y, sr)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx + 1e-10), shading='gouraud', cmap='viridis')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title('Spectrogram (Scipy)')\n",
    "    plt.colorbar(label='Intensity [dB]')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5308d",
   "metadata": {},
   "source": [
    "## Step 3: Example – Generate Spectrogram for One File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbefe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "# Install required library (run only once)\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c476a7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram saved to spectrograms/wasted_love_spectrogram.png\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"spectrograms\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the MP3 input and paths\n",
    "mp3_path = \"JJ - Wasted Love (Official Audio).mp3\"  # Your uploaded file\n",
    "wav_path = \"converted_audio.wav\"\n",
    "spectrogram_path = os.path.join(output_dir, \"wasted_love_spectrogram.png\")\n",
    "\n",
    "# Convert MP3 to WAV\n",
    "audio = AudioSegment.from_mp3(mp3_path)\n",
    "audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "# Define spectrogram generation function\n",
    "def generate_spectrogram(audio_path, save_path):\n",
    "    sr, y = wavfile.read(audio_path)\n",
    "    if y.ndim > 1:  # Convert stereo to mono if needed\n",
    "        y = y.mean(axis=1)\n",
    "    f, t, Sxx = spectrogram(y, sr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx + 1e-10), shading='gouraud', cmap='viridis')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.colorbar(label='Intensity [dB]')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# Generate and save the spectrogram\n",
    "generate_spectrogram(wav_path, spectrogram_path)\n",
    "print(f\"Spectrogram saved to {spectrogram_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39dd45c",
   "metadata": {},
   "source": [
    "## Step 4: Optional – Prepare for Clustering or SHAP Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a346683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SHAP or clustering, use the feature dataframe from the earlier notebook\n",
    "# Example: df_features.to_csv('features.csv')\n",
    "\n",
    "# Then you can import into this notebook and use SHAP or clustering libraries like sklearn or seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cafc8",
   "metadata": {},
   "source": [
    "# 4. Download the MP3 from preview_url, Convert, and Generate Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68584926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "preview_url = \"https://p.scdn.co/mp3-preview/...\"  # Replace with actual preview_url\n",
    "output_dir = \"spotify_previews\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "mp3_path = os.path.join(output_dir, \"track_preview.mp3\")\n",
    "wav_path = os.path.join(output_dir, \"track_preview.wav\")\n",
    "spectrogram_path = os.path.join(output_dir, \"track_spectrogram.png\")\n",
    "\n",
    "# === 1. Download the preview MP3 ===\n",
    "response = requests.get(preview_url)\n",
    "with open(mp3_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# === 2. Convert MP3 to WAV ===\n",
    "audio = AudioSegment.from_mp3(mp3_path)\n",
    "audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "# === 3. Generate Spectrogram from WAV ===\n",
    "y, sr = librosa.load(wav_path, sr=None)\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogram of Spotify Preview')\n",
    "plt.tight_layout()\n",
    "plt.savefig(spectrogram_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Spectrogram saved to: {spectrogram_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
